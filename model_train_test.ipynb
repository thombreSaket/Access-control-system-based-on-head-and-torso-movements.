{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a893e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import threading\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa84298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataframe:\n",
      "                   timestamp         X         Y         Z\n",
      "0    2017-03-31 13:42:19.011  0.010653  0.002131 -0.023436\n",
      "1    2017-03-31 13:42:19.211 -0.005326  0.001065 -0.051133\n",
      "2    2017-03-31 13:42:19.409 -0.022371  0.020240 -0.007457\n",
      "3    2017-03-31 13:42:19.601  0.053263 -0.024501 -0.099070\n",
      "4    2017-03-31 13:42:19.832  0.242880  0.023436  0.450607\n",
      "...                      ...       ...       ...       ...\n",
      "5545 2017-03-31 13:45:02.703 -0.040000  0.080000  0.000000\n",
      "5546 2017-03-31 13:45:02.706 -0.030000  0.090000  0.000000\n",
      "5547 2017-03-31 13:45:02.732 -0.040000  0.050000  0.000000\n",
      "5548 2017-03-31 13:45:02.763 -0.050000  0.090000 -0.010000\n",
      "5549 2017-03-31 13:45:02.767 -0.140000 -0.210000  0.030000\n",
      "\n",
      "[6533 rows x 4 columns]\n",
      "\n",
      "Timestamps Dataframe:\n",
      "                   timestamp\n",
      "0    2017-03-31 13:42:19.011\n",
      "1    2017-03-31 13:42:19.211\n",
      "2    2017-03-31 13:42:19.409\n",
      "3    2017-03-31 13:42:19.601\n",
      "4    2017-03-31 13:42:19.832\n",
      "...                      ...\n",
      "5545 2017-03-31 13:45:02.703\n",
      "5546 2017-03-31 13:45:02.706\n",
      "5547 2017-03-31 13:45:02.732\n",
      "5548 2017-03-31 13:45:02.763\n",
      "5549 2017-03-31 13:45:02.767\n",
      "\n",
      "[6533 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell is used to run the model on a single User's Glass and phone data. This is done to make sure \n",
    "what contents are stored in the data frame. \n",
    "'''\n",
    "\n",
    "# Define paths to folders containing training data\n",
    "glass_folder_path = r'C:/Users/sudha/Desktop/Semester 2/MLS/Project 2/New folder/Training Data/User001/Glass'\n",
    "htc_folder_path = r'C:/Users/sudha/Desktop/Semester 2/MLS/Project 2/New folder/Training Data/User001/HTC - front'\n",
    "\n",
    "# Define function to read gyro data from a given file\n",
    "def read_gyro_data(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=[0, 1, 2, 3])\n",
    "    df.columns = ['timestamp', 'X', 'Y', 'Z']\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S:%f')\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Read gyro data from both files\n",
    "glass_df = read_gyro_data(os.path.join(glass_folder_path, 'gyroData.csv'))\n",
    "htc_df = read_gyro_data(os.path.join(htc_folder_path, 'gyroDataM.csv'))\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "combined_df = pd.concat([glass_df, htc_df])\n",
    "\n",
    "# Create separate dataframe for timestamps\n",
    "timestamps_df = combined_df[['timestamp']].copy()\n",
    "\n",
    "print('Combined Dataframe:')\n",
    "print(combined_df)\n",
    "\n",
    "print('\\nTimestamps Dataframe:')\n",
    "print(timestamps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac101177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Features:\n",
      "                 X\n",
      "count  6533.000000\n",
      "mean      0.029137\n",
      "std       1.103641\n",
      "min      -7.911719\n",
      "25%      -0.470000\n",
      "50%       0.060720\n",
      "75%       0.770000\n",
      "max       4.150000\n",
      "X Skew: -0.5723376389831188\n",
      "Y Features:\n",
      "                 Y\n",
      "count  6533.000000\n",
      "mean     -0.009780\n",
      "std       1.225926\n",
      "min      -6.150000\n",
      "25%      -0.680000\n",
      "50%       0.020240\n",
      "75%       0.660000\n",
      "max       6.293582\n",
      "Y Skew: -0.03649729527872387\n",
      "Z Features:\n",
      "                 Z\n",
      "count  6533.000000\n",
      "mean     -0.056905\n",
      "std       0.913052\n",
      "min      -5.303952\n",
      "25%      -0.500000\n",
      "50%       0.030000\n",
      "75%       0.540000\n",
      "max       4.040000\n",
      "Z Skew: -0.5868365828180566\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This cell deals with the feature extraction of the data frame created above. This cell is specifically made\n",
    "to print out how the extracted features look and how are they stored.\n",
    "'''\n",
    "# Extract features from columns X, Y, and Z\n",
    "x_features = combined_df[['X']].describe()\n",
    "y_features = combined_df[['Y']].describe()\n",
    "z_features = combined_df[['Z']].describe()\n",
    "\n",
    "x_skew = combined_df['X'].skew()\n",
    "y_skew = combined_df['Y'].skew()\n",
    "z_skew = combined_df['Z'].skew()\n",
    "\n",
    "\n",
    "# Print the extracted features\n",
    "print('X Features:')\n",
    "print(x_features)\n",
    "print('X Skew:', x_skew)\n",
    "\n",
    "print('Y Features:')\n",
    "print(y_features)\n",
    "print('Y Skew:', y_skew)\n",
    "\n",
    "print('Z Features:')\n",
    "print(z_features)\n",
    "print('Z Skew:', z_skew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84807d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Training Phase\n",
    "\n",
    "'''\n",
    "# Define parent folder path\n",
    "parent_folder_path = r'C:\\Users\\sudha\\Desktop\\Semester 2\\MLS\\Project 2\\New folder\\Data of Head and Torso movement\\data\\Training Data\\\\'\n",
    "\n",
    "# Define function to read gyro data from a given file\n",
    "def read_gyro_data(file_path):\n",
    "    df = pd.read_csv(file_path, usecols=[0, 1, 2, 3])\n",
    "    df.columns = ['timestamp', 'X', 'Y', 'Z']\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S:%f')\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    return df   \n",
    "\n",
    "\n",
    "# Define column and index labels\n",
    "col_labels = pd.MultiIndex.from_tuples([('count', 'X'), ('count', 'Y'), ('count', 'Z'),\n",
    "                                        ('mean', 'X'), ('mean', 'Y'), ('mean', 'Z'),\n",
    "                                        ('std', 'X'), ('std', 'Y'), ('std', 'Z'),\n",
    "                                        ('min', 'X'), ('min', 'Y'), ('min', 'Z'),\n",
    "                                        ('25%', 'X'), ('25%', 'Y'), ('25%', 'Z'),\n",
    "                                        ('50%', 'X'), ('50%', 'Y'), ('50%', 'Z'),\n",
    "                                        ('75%', 'X'), ('75%', 'Y'), ('75%', 'Z'),\n",
    "                                        ('max', 'X'), ('max', 'Y'), ('max', 'Z')])\n",
    "\n",
    "\n",
    "\n",
    "# Create empty dataframe with column and index labels\n",
    "empty_df = pd.DataFrame(columns=col_labels).assign(Label=[])\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 18):\n",
    "    user_folder_path = os.path.join(parent_folder_path, f'User{i:03}')\n",
    "    glass_file_path = os.path.join(user_folder_path, 'Glass/gyroData.csv')\n",
    "    htc_file_path = os.path.join(user_folder_path, 'HTC - front/gyroDataM.csv')\n",
    "    glass_df = read_gyro_data(glass_file_path)\n",
    "    htc_df = read_gyro_data(htc_file_path)\n",
    "    #glass_features = glass_df[['X', 'Y', 'Z']].describe()\n",
    "    glass_features = glass_df[['X', 'Y', 'Z']].describe().stack().to_frame().transpose()\n",
    "    glass_features = glass_features .assign(Label=[f'User{i:03}_glass'])\n",
    "    empty_df = pd.concat([empty_df, glass_features])\n",
    "    \n",
    "    htc_features = htc_df[['X', 'Y', 'Z']].describe().stack().to_frame().transpose()\n",
    "    htc_features = htc_features .assign(Label=[f'User{i:03}_htc'])\n",
    "    empty_df = pd.concat([empty_df, htc_features])\n",
    "\n",
    "copy_df = empty_df\n",
    "    \n",
    "X_train = copy_df.drop(columns=[\"Label\"])\n",
    "y_train = empty_df[\"Label\"]\n",
    "\n",
    "print(len(y_train))\n",
    "\n",
    "# Train random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c585166",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Testing Phase\n",
    "\n",
    "'''\n",
    "\n",
    "glass_folder_path_test = r'C:\\Users\\sudha\\Desktop\\Semester 2\\MLS\\Project 2\\New folder\\Data of Head and Torso movement\\data\\Testing Data\\\\'\n",
    "#htc_folder_path_test = r'C:\\Users\\sudha\\Desktop\\Semester 2\\MLS\\Project 2\\New folder\\Data of Head and Torso movement\\data\\Testing Data\\\\\\'\n",
    "\n",
    "col_labels = pd.MultiIndex.from_tuples([('count', 'X'), ('count', 'Y'), ('count', 'Z'),\n",
    "                                        ('mean', 'X'), ('mean', 'Y'), ('mean', 'Z'),\n",
    "                                        ('std', 'X'), ('std', 'Y'), ('std', 'Z'),\n",
    "                                        ('min', 'X'), ('min', 'Y'), ('min', 'Z'),\n",
    "                                        ('25%', 'X'), ('25%', 'Y'), ('25%', 'Z'),\n",
    "                                        ('50%', 'X'), ('50%', 'Y'), ('50%', 'Z'),\n",
    "                                        ('75%', 'X'), ('75%', 'Y'), ('75%', 'Z'),\n",
    "                                        ('max', 'X'), ('max', 'Y'), ('max', 'Z')])\n",
    "\n",
    "\n",
    "\n",
    "# Create empty dataframe with column and index labels\n",
    "test_df = pd.DataFrame(columns=col_labels).assign(Label=[])\n",
    "user_folder_path = os.path.join(parent_folder_path, f'User002')\n",
    "glass_file_path = os.path.join(user_folder_path, 'HTC - front/gyroDataM.csv')\n",
    "\n",
    "test_glass_df = read_gyro_data(glass_file_path)\n",
    "\n",
    "#glass_features = glass_df[['X', 'Y', 'Z']].describe()\n",
    "test_glass_features = test_glass_df[['X', 'Y', 'Z']].describe().stack().to_frame().transpose()\n",
    "test_glass_features = test_glass_features .assign(Label=[f'User002_htc'])\n",
    "test_df = pd.concat([test_df, test_glass_features])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa74e098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted user is: ['User002_htc']\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Outcome Prediction\n",
    "\n",
    "'''\n",
    "\n",
    "copy_test = test_df\n",
    "x_test = copy_test.drop(columns=[\"Label\"])\n",
    "y_test = test_df[\"Label\"]\n",
    "\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "print(\"The predicted user is:\", y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c51be930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLOWED\n"
     ]
    }
   ],
   "source": [
    "authorized_users = [\"User001_glass\", \"User001_htc\", \"User002_glass\", \"User002_htc\", \"User005_glass\", \"User005_htc\", \"User015_glass\", \"User015_htc\"]\n",
    "\n",
    "if y_pred in authorized_users:\n",
    "    print(\"ALLOWED\")\n",
    "else:\n",
    "    print(\"DENIED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
